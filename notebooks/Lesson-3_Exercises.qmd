---
title: "Tema 3: Ejercicios"
format:
  html:
    code-copy:       true
    code-tools:      true
    embed-resources: true
    theme:           ../www/extra-styles.scss
    toc:             true
    toc-location:    left
callout-appearance: minimal
---

# Introducción

En este hemos visto los fundamentos del modelado Bayesiano, y vamos a aplicarlos desde un punto de vista teórico en los ejercicios a continuación.

En primer lugar, configuramos el entorno para ejecutar el código.

```{r setup}
#| message: false

# Paquetes:
library(tidyverse)
library(RColorBrewer)


# Configuración de la salida gráfica:

PALETA <- brewer.pal(8, "Set2") # Colores por defecto
color_defecto  <- PALETA[1]
options(ggplot2.discrete.colour = PALETA)

theme_set(theme_bw()) # Tema "neutro" para la representación gráfica
```

Verás que solamente necesitamos el paquete {tidyverse}, para manipular datos, y configurar la salida gráfica (el paquete {RColorBrewer} sólo se utiliza para obtener una paleta de colores agradable y accesible para personas con ceguera al color).
No hace falta ningún paquete para análisis y modelado Bayesiano, ya que los modelos que vamos a estimar se basan en las propiedades analíticas de las *distribuciones conjugadas*.

# Ejercicio 1

## Distribución uniforme

A continuación se muestra el código en R para representar la distribución uniforme $x \sim U(0, 1)$:

```{r ejemplo-uniforme}
PREC     <- 1e-3 # Precisión para representar la función de densidad (milésimas)
DENS_INF <- 0    # Rango inferior de la función de densidad
DENS_SUP <- 1    # Rango superior de la función de densidad

uniforme <- tibble( # Esta función crea un "data.frame" o tabla de datos
  variable = seq(from = DENS_INF, to = DENS_SUP, by = PREC),
  densidad = variable |> dunif(min = DENS_INF, max = DENS_SUP)
)

uniforme |> glimpse() # Muestra el objeto con los datos, contiene 2 columnas 

uniforme |> # Usando la tabla de datos antes creada, crea un objeto gráfico
  ggplot(mapping = aes(x = variable, y = densidad)) + # "Mapea" columnas a
                                                      #   coordenadas
  geom_line(color = color_defecto) + # Representa mediante una línea continua
  
  ylim( # Fija el límite inferior a 0 para mostrar el eje y completo:
    0,  # (Usa la propia distribución para establecer el límite superior)
    uniforme |> pull(densidad) |> max()
  )
```

## Distribución normal

Aplicando un código similar, se puede representar una distribución normal estandarizada $x \sim N(0, 1)$:

```{r ejemplo-normal}
DENS_INF <- -4 # Usamos un rango más adecuado para la normal estandarizada
DENS_SUP <-  4

normal <- tibble( # Reutilizamos `PREC` del "chunk" de código anterior
  variable = seq(from = DENS_INF, to = DENS_SUP, by = PREC),
  densidad = variable |> dnorm()
)

# Al cubrir la distribución el rango desde 0 hasta el máximo, en este caso no
#   es necesario establecer los límites manualmente
normal |>
  ggplot(mapping = aes(x = variable, y = densidad)) +
  geom_line(color = color_defecto)
```

Como puedes ver, los límites se establecen automáticamente para cubrir todo el rango de la distribución (no hace falta fijarlos).
Al haber valores próximos a 0, tampoco es necesario establecer el límite inferior manualmente.

## Integración "numérica"

Haciendo uso de los valores generados de una distribución, podemos operar con ellos para obtener los resultados de "integrar" esa función, pero haciéndolo de forma numérica.

Al obtener "valores equiespaciados" de la distribución, lo que estamos obteniendo es una "rejilla" de valores.
La integración será una suma de "rectángulos", de altura igual a la densidad en ese punto, con base centrada en ese punto y extenciéndose `PREC/2` hacia cada lado (y por tanto de anchura `PREC`).

Utilizando esta "integral numérica", podemos obtener ciertos valores de la distribución.
Por ejemplo, la integral en todo el dominio de la variable debería tener un valor de 1.

```{r integral-uniforme}
uniforme |> summarize(integral = PREC * sum(densidad))
```

En el caso de la distribución uniforme, tenemos valores "centrados" en 0 y 1, por lo que los intervalos de los extremos se extienden hasta `-PREC/2` y `1 + PREC/2`.
Podríamos "restar medio valor" de la densidad en cada extremo para obtener una integral más precisa:

```{r}
uniforme |> summarize(
  integral = PREC * (sum(densidad) - 0.5 * (first(densidad) + last(densidad)))
)
```

En el caso de la distribución normal el cálculo de la integral se haría igual:

```{r integral-normal}
normal |> summarize(
  integral = sum(densidad) * PREC
)
```

En este caso, el dominio es infinito, pero nos hemos restringido al rango $[`{r} DENS_INF`, `{r} DENS_SUP`]$.
Por lo tanto, estamos desechando la parte de la distribución que está en las "colas".
También, cuanto mayor sea la precisión, más se acercará la aproximación mediante "rectángulos" a la curva real.

```{r integral-normal-mas-precisa}
tibble( # Ampliando el rango a [-10, 10]:
  variable = seq(from = -10, to = 10, by = PREC),
  densidad = variable |> dnorm()
) |>
  summarize(integral = sum(densidad) * PREC)

tibble( # Usando precisión de "millonésimas":
  variable = seq(from = DENS_INF, to = DENS_SUP, by = 1e-6),
  densidad = variable |> dnorm()
) |>
  summarize(integral = sum(densidad) * 1e-6) # Misma precisión en la integral
```

En general, las aproximaciones iniciales pueden ser válidas.
Si lo necesitamos, podemos "normalizar" por la integral.
Los siguiente ejemplos, triviales, pueden ayudarnos más adelante:

```{r integral-normalizada}
uniforme |> summarize(
  integral = PREC * sum(densidad),
  integral = integral / integral # Normalización
)

normal |> summarize(
  integral = PREC * sum(densidad),
  integral = integral / integral # Normalización
)
```

## Práctica

Calcula o comprueba las siguientes respuestas usando comandos de R:

### Pregunta 1

-   ¿Cuál es el valor máximo de la función de densidad?

::: {#respuesta-1 .callout-note}
La distribución uniforme $U(0,1)$ tiene una función de densidad constante en todo el intervalo.
Es decir, la densidad en todos los puntos es la misma. Como es constante y su valor es 1, el valor máximo de la función de densidad es 1.

En el caso de la distribución normal, ésta tiene forma de campana y su valor máximo ocurre en el centro de la distribución.

```{r}
x_normal <- seq(-4, 4, by = 0.01) 
densidad_normal <- dnorm(x_normal, mean = 0, sd = 1)
max(densidad_normal)
```
El valor máximo en la distribución normal es 0.3989423
:::

### Pregunta 2

-   ¿Para qué valor de la variable aleatoria se da? ¿Cómo llamarías a ese valor?

::: {#respuesta-2 .callout-note}
En la distribución uniforme $U(0,1)$, la función de densidad es constante en todo el intervalo, por lo que no existe un único valor de la variable aleatoria en el cual se dé el valor máximo de la función de densidad.
En la distribución normal $N(0,1)$, el valor máximo de la densidad ocurre en $x=0$, que es el pico de la distribución y también el valor de la media.
:::

### Pregunta 3

-   El valor máximo, ¿puede ser mayor que 1? Justifica tu respuesta.

::: {#respuesta-3 .callout-note}
Sí. Voy a explicar por qué con un ejemplo. 

Imagina que tenemos una pipeta y estamos midiendo la concentración de bacterias.
Supongamos que estamos midiendo la densidad de bacterias por microlitro. Si la concentración de bacterias es muy alta, es posible que en un volumen muy pequeño haya muchas bacterias.
Por ejemplo, si en 1 microlitro hay 1000 bacterias, la densidad será de 1000 bacterias por microlitro, lo que es mayor que 1.
Importante: la probabilidad no es lo mismo que la densidad.
Aunque la densidad de bacterias en un volumen pequeño sea mayor que 1, la probabilidad total de encontrar bacterias en la pipeta sigue siendo 1.
:::

### Pregunta 4

-   Calcula y representa la función de distribución de la variable normal

*(Ejecuta `?cumsum` para consultar la ayuda de esa función).*

::: {#respuesta-4 .callout-note}
```{r}
# Definimos el rango de valores para la variable normal
DENS_INF <- -4
DENS_SUP <- 4
PREC <- 1e-3  

# Creaamos tabla de datos con valores equiespaciados
normal_cdf <- tibble(
  variable = seq(from = DENS_INF, to = DENS_SUP, by = PREC),
  distribucion = pnorm(variable) 
)

# Graficamos la CDF
ggplot(normal_cdf, aes(x = variable, y = distribucion)) +
  geom_line(color = "blue") +
  labs(title = "Función de Distribución Acumulada (CDF) de N(0,1)",
       x = "x", y = "F(x)") +
  theme_minimal()
```
La función de distribución acumulada de una variable aleatoria $X$ se define como $F(x)=P(X≤x)$, donde $F(x)$ es la CDF, $P$ representa la probabilidad y $x$ es un valor específico de la variable aleatoria. La CDF es una función no decreciente que varía de 0 a 1. A medida que $x$ se acerca al infinito negativo, la CDF tiende a 0, y cuando $x$ se aproxima al infinito positivo, la CDF tiende a 1.
:::

### Pregunta 5

-   Calcula el valor esperado de la distribución normal.

::: {#respuesta-5 .callout-note}
La media de la distribución normal estándar es cero y la desviación típica es uno.
```{r}
media <- 0
desviacion_estandar <- 1
valor_esperado <- media
valor_esperado
```
En una distribución normal estándar el valor esperado es igual a la media.
:::

# Ejercicio 2

## Distribución Beta

### Pregunta 6

-   Representa una distribución Beta con parámetros $\alpha$ = $\beta$ = 1, $Beta(1, 1)$. Ajusta los ejes correctamente, si hace falta, como en la distribución uniforme.

*(Si no sabes qué limites utilizar, consulta la ayuda de `dbeta()`).*

::: {#respuesta-6 .callout-note}
```{r}
x_beta <- seq(0, 1, by = 0.01)
densidad_beta <- dbeta(x_beta, shape1 = 1, shape2 = 1)

plot(x_beta, densidad_beta, type = "l", col = "blue", lwd = 2,
     main = "Distribución Beta con α = 1 y β = 1",
     xlab = "Valor de x", ylab = "Densidad")
```
El gráfico es una línea horizontal, ya que la densidad es constante e igual a 1 en todo el intervalo. Es una distribución uniforme porque todos los resultados posibles tienen la misma probabilidad de ocurrir. 
:::

### Pregunta 7

-   ¿Qué forma tiene?

::: {#respuesta-7 .callout-note}
El gráfico se ve como una línea plana, lo que indica una probabilidad constante. 
:::

## Parámetros de la distribución Beta

### Pregunta 8

-   Prueba con diferentes valores de $\alpha$ y $\beta$.

::: {#respuesta-8 .callout-note}
```{r}
x <- seq(0, 1, length.out = 1000)
alpha_values <- c(1, 2, 5, 3)
beta_values <- c(3, 5, 1, 3)
par(mfrow=c(2,2))
for (i in 1:length(alpha_values)) {
  alpha <- alpha_values[i]
  beta <- beta_values[i]
  y <- dbeta(x, shape1 = alpha, shape2 = beta)
  plot(x, y, type = "l", col = "blue", lwd = 2, 
       main = paste("Beta(", alpha, ",", beta, ")"), 
       xlab = "x", ylab = "Densidad")
}
```
:::

### Pregunta 9

-   ¿Qué ocurre a medida que van creciendo?

::: {#respuesta-9 .callout-note}
A medida que alpha y beta crecen de manera proporcional, la distribución tiende a concentrarse más en el centro, cerca de 0.5, y se hace más estrecha. Como no hay una inclinación hacia un valor específico, decimos que hay indecisión. Por poner un ejemplo: imagina que no sabemos si un huracán va a pasar o no por Estados Unidos. Sin embargo, a medida que pasan los días y obtenemos más información (como predicciones meteorológicas más precisas), la incertidumbre se reduce y la probabilidad de que el huracán pase por EEUU comienza a inclinarse hacia un valor más claro (cerca de 0 o 1), y la distribución se hace más estrecha, reflejando una mayor certeza. Si alpha (la probabilidad de que el huracán pase) crece más que beta (la probabilidad de que no pase), la distribución Beta se sesga hacia 1.
:::

### Pregunta 10

-   ¿Qué ocurre cuando son iguales? ¿Y cuándo son distintos?

::: {#respuesta-10 .callout-note}
Cuando alpha y beta son iguales, la distribución beta es simétrica alrededor de 0,5, lo que significa que hay la misma probabilidad de que la variable aleatoria tome valores cercanos a 0 o a 1. Un ejemplo: imagina que estás eligiendo entre dos sabores de helado y no tienes preferencia por ninguno. Entonces, la probabilidad de que elijas uno u otro es igual, por eso la distribución es simétrica. Es decir, estás completamente indeciso.
Pero si alpha y beta son distintos, la distribución se sesga hacia el lado del valor más grande. Supón que ves un helado de chocolate que te encanta. Si alpha (la preferencia por el chocolate) es mayor que beta (otro sabor menos calórico), la distribución se inclinará hacia el chocolate, es decir, el valor más cercano a 1. Si beta es mayor, se inclinará hacia el sabor que prefieres menos (más cercano a 0). Esto significa que la probabilidad de elegir chocolate, el sabor que te encanta, es mayor.
:::

### Pregunta 11

-   ¿Qué ocurre si tienen valores ligeramente superiores a 1?

::: {#respuesta-11 .callout-note}
La distribución Beta se concentrará más alrededor de 0.5. Vamos con otro ejemplo: imagina que vas al supermercado y estás considerando entre dos pastas de dientes. No tienes una preferencia clara porque son muy parecias en cuanto a precio y características, pero después de pensarlo un poco es más probable que elijas una que la otra, aunque todavía tienes dudas. Así que la distribución refleja esta probabilidad equilibrada, pero un poco más enfocada hacia el centro (0.5).
:::

### Pregunta 12

-   ¿Qué ocurre si tienen valores por debajo de 1?

::: {#respuesta-12 .callout-note}
La distribución Beta se inclina hacia los extremos, cerca de 0 o 1. La distribución tiene forma de U. Esto significa que la probabilidad de que algo suceda o no es casi la misma. Por poner un ejemplo: si hay un nueva candidata en las elecciones y no tenemos mucha información sobre ella, no sabemos si va a ganar o perder, por lo que la probabilidad de que gane o pierda es más o menos igual. Por eso vemos esta forma de U.
:::

# Ejercicio 3

*(NOTA: Para todas las distribuciones, utiliza el valor de `PREC` definido en el ejercicio 1.)*

## Modelo beta-binomial

En el departamento de investigación de mercado de tu empresa quieren saber la tasa de aceptación de la nueva app que quieren lanzar.
Para ello, han probado la app con una muestra (asume m.a.s.) de $n$ potenciales usuarios/as, y se las pedido que indiquen si descargarían o no la app.

El jefe del departamento de analítica te asigna al proyecto y te pide que ajustes un modelo beta-binomial "no informativo" para responder a la pregunta de investigación.

### Pregunta 13

-   ¿Cómo se representa la "tasa de aceptación" en el modelo?

::: {#respuesta-13 .callout-note}
Se representa como $p$, que es la probabilidad de que un usuario descargue la app. Como no sabemos su valor, asumimos que $p$ sigue una distribución Beta, lo que significa que puede tomar cualquier valor entre 0 y 1. Como no tenemos información previa, usamos una distribución no informativa. Para esto, usamos $α=1$ y $β=1$, que asigna la misma probabilidad a todos los valores posibles de $p$.
:::

### Pregunta 14

-   ¿Qué distribución previa utilizarías para esa tasa de aceptación? Formúlala y represéntala gráficamente.

*(Ajusta los ejes correctamente, si hace falta, como en la distribución uniforme).*

::: {#respuesta-14 .callout-note}
Utilizaría una distribución Beta no informativa, es decir, $p∼Beta(1, 1)$, ya que asumo que todos los valores de $p$ son igualmente probables. Usamos esta distribución porque no tenemos información previa sobre la tasa de aceptación de la app. 
```{r}
alpha_prior <- 1
beta_prior <- 1
prec <- 1e-3 
p_values <- seq(0, 1, by = prec)
# Calculamos la densidad de la distribución Beta(1,1)
densidad <- dbeta(p_values, shape1 = alpha_prior, shape2 = beta_prior)
# Creamos el gráfico
ggplot(data.frame(p = p_values, density = dbeta(p_values, alpha_prior, beta_prior)), aes(x = p, y = density)) +
  geom_line(color = "blue") +
  labs(title = "Distribución Beta(1,1) - Distribución Previa No Informativa",
       x = "p (Probabilidad de aceptación)",
       y = "Densidad") +
  theme_bw()
```
:::

### Pregunta 15

-   Supón que $y$ es el número de usuarios/as que han respondido que "Sí" descargarían la app. Formula la verosimilitud del modelo.

::: {#respuesta-15 .callout-note}
El número de usuarios $y$ que responden $sí$ sigue una distribución binomial, ya que cada usuario puede responder $sí$ y $No$. El modelo asume que cada usuario decide de manera independiente y con la misma probabilidad $p$ si va a descargar la app o no. 

$$
\mathcal{P}(y | p, n) = \binom{n}{y} p^y (1-p)^{n-y}
$$
:::

## Ajuste del modelo

-   El departamento de investigación de mercado te da acceso a los siguientes datos de la muestra:

```{r beta-binomial-muestra}
aceptacion_muestra <- tibble(
  id_participante   = 1:22,
  resp_descarga_app = c(
    "Si", "Si", "No", "No", "Si", "Si", "Si", "Si", "No", "Si", "Si",
    "Si", "Si", "Si", "Si", "Si", "No", "Si", "No", "Si", "Si", "Si"
  )
)
```

### Pregunta 16

-   Obtén, en base a estos datos, la distribución posterior de la tasa de aceptación (en forma analítica), y represéntala junto a la distribución previa.

::: {#respuesta-16 .callout-note}

```{r}
# Datos de la muestra
aceptacion_muestra <- tibble(
  id_participante   = 1:22,
  resp_descarga_app = c(
    "Si", "Si", "No", "No", "Si", "Si", "Si", "Si", "No", "Si", "Si",
    "Si", "Si", "Si", "Si", "Si", "No", "Si", "No", "Si", "Si", "Si"
  )
)

# Contamos los "Sí"
y <- sum(aceptacion_muestra$resp_descarga_app == "Si")
n <- nrow(aceptacion_muestra)

# Parámetros de la distribución Beta a priori
alpha_prior <- 1
beta_prior <- 1

# Parámetros de la distribución Beta posterior
alpha_post <- alpha_prior + y
beta_post <- beta_prior + (n - y)

# Generamos valores de p en el intervalo (0,1)
prec <- 1e-3
p_values <- seq(0, 1, by = prec)

# Calculamos las densidades de las distribuciones Beta a priori y a posteriori
densidad_prior <- dbeta(p_values, shape1 = alpha_prior, shape2 = beta_prior)
densidad_post <- dbeta(p_values, shape1 = alpha_post, shape2 = beta_post)

# Graficamos las distribuciones
ggplot() +
  geom_line(aes(x = p_values, y = densidad_prior), color = "blue", linewidth = 1.2, linetype = "dashed") +
  geom_line(aes(x = p_values, y = densidad_post), color = "red", linewidth = 1.2) +
  labs(
    title = "Distribuciones Beta: A Priori vs Posterior",
    x = "Tasa de aceptación (p)",
    y = "Densidad",
    caption = "Distribución a priori (azul) y posterior (roja)"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```

Primero, usamos $Beta(1,1)$ ya que antes de ver los datos asumimos que cualquier valor entre 0 y 1 es igualmente probable. 
A continuación, usamos los datos observados para actualizar la distribución a priori. Con 17 respuestas afirmativas y 5 negativas. Lo que significa que $αposterior=1+17=18$ y $βposterior=1+(22−17)=6$
El gráfico compara la distribución a priori, en azul, y la distribución posterior, en rojo. De este modo, podemos observar cómo cambia la distribución de $p$ después de observar los datos. 
La distribución posterior refleja nuestro conocimiento actualizado sobre la tasa de aceptación $p$ después de observar los datos. A medida que incorporamos las respuestas afirmativas y negativas, la distribución se ajusta, concentrándose alrededor de un valor más probable de $p$.
:::

### Pregunta 17

-   Obtén el valor esperado y la moda de la distribución posterior. ¿Cómo los interpretarías?

*(Nota: Ten en cuenta la "precisión" al calcular el "peso" de cada muestra.)*

::: {#respuesta-17 .callout-note}

```{r}
# Parámetros de la distribución Beta a priori
alpha_prior <- 1
beta_prior <- 1

# Contar los "Sí" (y) en los datos
y <- sum(aceptacion_muestra$resp_descarga_app == "Si")
n <- nrow(aceptacion_muestra)

# Parámetros de la distribución Beta posterior
alpha_post <- alpha_prior + y
beta_post <- beta_prior + (n - y)

# Calcular el valor esperado de la distribución posterior
valor_esperado <- alpha_post / (alpha_post + beta_post)

# Calcular la moda de la distribución posterior
moda <- (alpha_post - 1) / (alpha_post + beta_post - 2)

# Mostrar los resultados
valor_esperado
moda
```
La cantidad de respuestas afirmativas es $y=17$ y el total de respuestas es $n=22$. Los parámetros de la distribución posterior son: $αposterior=1+17=18$ y $βposterior=1+(22−17)=6$
El valor esperado de la distribución Beta es: 
$$
\mathcal{E}(p) = \frac{\alpha_{\text{posterior}}}{\alpha_{\text{posterior}} + \beta_{\text{posterior}}}
$$
La fórmula para la moda: 
$$
\mathcal{M}(p) = \frac{\alpha_{\text{posterior}} - 1}{\alpha_{\text{posterior}} + \beta_{\text{posterior}} - 2}
$$
Sustituyendo los valores, la moda es $0.7725$
El valor esperado de la distribución posterior es aproximadamente 0.75, lo que significa que, basándonos en los datos disponibles, estimamos que aproximadamente el 75% de los usuarios aceptarán descargar la app. La moda es ligeramente mayor (0.7725), lo que indica el valor de $p$ que tiene la mayor probabilidad de ocurrir, dadas las respuestas observadas.
:::

## Ajuste con una nueva muestra

-   El director de investigación de mercado no está totalmente seguro con los resultados, y pide a su departamento recoger una nueva muestra, mayor, para el estudio. Te dan acceso a los siguientes datos de la nueva muestra:

```{r beta-binomial-muestra2}
aceptacion_muestra_2 <- tibble(
  id_participante   = 1:113,
  resp_descarga_app = c(
    "Si", "Si", "No", "No", "Si", "Si", "Si", "Si", "No", "Si", "Si",
    "Si", "Si", "Si", "Si", "Si", "No", "Si", "No", "Si", "Si", "Si", 
    "No", "Si", "Si", "Si", "Si", "No", "No", "Si", "No", "Si", "Si", 
    "Si", "Si", "Si", "No", "Si", "No", "No", "Si", "No", "Si", "Si", 
    "No", "No", "No", "Si", "No", "No", "Si", "Si", "No", "No", "Si", 
    "No", "Si", "No", "No", "No", "Si", "Si", "No", "Si", "Si", "No", 
    "Si", "Si", "No", "Si", "Si", "No", "Si", "No", "Si", "No", "Si", 
    "No", "No", "No", "Si", "Si", "No", "No", "Si", "Si", "No", "No", 
    "No", "Si", "Si", "No", "Si", "Si", "No", "Si", "Si", "Si", "Si", 
    "No", "Si", "No", "No", "No", "No", "No", "Si", "No", "No", "Si", 
    "Si", "Si", "Si"
  )
)
```

### Pregunta 18

-   ¿Qué distribución previa utilizarías en esta ocasión? Formúlala.

::: {#respuesta-18 .callout-note}
Dado que ya hemos analizado una muestra anterior con 22 respuestas y obtenido una distribución posterior $Beta(1+17,1+5)=Beta(18,6)$, podemos usar esta distribución como la nueva distribución previa para actualizarla con la nueva muestra. 


```{r}
# Cargar los datos de la nueva muestra
aceptacion_muestra_2 <- tibble(
  id_participante   = 1:113,
  resp_descarga_app = c(
    "Si", "Si", "No", "No", "Si", "Si", "Si", "Si", "No", "Si", "Si",
    "Si", "Si", "Si", "Si", "Si", "No", "Si", "No", "Si", "Si", "Si", 
    "No", "Si", "Si", "Si", "Si", "No", "No", "Si", "No", "Si", "Si", 
    "Si", "Si", "Si", "No", "Si", "No", "No", "Si", "No", "Si", "Si", 
    "No", "No", "No", "Si", "No", "No", "Si", "Si", "No", "No", "Si", 
    "No", "Si", "No", "No", "No", "Si", "Si", "No", "Si", "Si", "No", 
    "Si", "Si", "No", "Si", "Si", "No", "Si", "No", "Si", "No", "Si", 
    "No", "No", "No", "Si", "Si", "No", "No", "Si", "Si", "No", "No", 
    "No", "Si", "Si", "No", "Si", "Si", "No", "Si", "Si", "Si", "Si", 
    "No", "Si", "No", "No", "No", "No", "No", "Si", "No", "No", "Si", 
    "Si", "Si", "Si"
  )
)

# Contamos los "Sí" en la nueva muestra
y_new <- sum(aceptacion_muestra_2$resp_descarga_app == "Si")
n_new <- nrow(aceptacion_muestra_2)

# Imprimimos para verificar los resultados
print(paste("Número de respuestas afirmativas:", y_new))
print(paste("Tamaño total de la muestra:", n_new))

# Parámetros de la distribución previa de la nueva muestra (posterior del ejercicio anterior)
alpha_prior_new <- 18
beta_prior_new <- 6

# Parámetros de la distribución Beta posterior para la nueva muestra
alpha_post_2 <- alpha_prior_new + y_new
beta_post_2 <- beta_prior_new + (n_new - y_new)

# Imprimir los resultados
print(paste("Alpha posterior 2:", alpha_post_2))
print(paste("Beta posterior 2:", beta_post_2))
```
:::

### Pregunta 19

-   Obtén la distribución posterior analítica después de esta segunda muestra, represéntala junto con las dos distribuciones anteriores, y obtén los estimadores posteriores esperado y modal.

::: {#respuesta-19 .callout-note}
La distribución posterior después de la nueva muestra será $Beta(83,54)$
El valor esperado de la distribución Beta es: 

$$
\mathcal{E}(p) = \frac{\alpha_{\text{posterior}}}{\alpha_{\text{posterior}} + \beta_{\text{posterior}}}
$$
Sustituyendo los valores:

$$
\mathcal{E}(p) = \frac{83}{83 + 54} = \frac{83}{137} \approx 0.606
$$
La fórmula para la moda: 

$$
\mathcal{M}(p) = \frac{\alpha_{\text{posterior}} - 1}{\alpha_{\text{posterior}} + \beta_{\text{posterior}} - 2}
$$
Sustituyendo los valores:

$$
\mathcal{M}(p) = \frac{83 - 1}{83 + 54 - 2} = \frac{82}{135} \approx 0.607
$$
La actualización de la distribución posterior con la nueva muestra nos permite afinar aún más nuestra estimación de la tasa de aceptación: ahora el valor esperado (0.606) es ligeramente menor que el de la muestra anterior (0.75) debido a la mayor cantidad de datos disponibles.
:::

## Ajuste con las muestras colapsadas

Supón que el director de investigación de mercado no estaba contento con la muestra inicial y pidió recoger más muestra antes de darte acceso a los datos.
Cuando recibes los datos, recibes las dos muestras colapsadas, sin saber qué participantes eran de la primera o de la segunda muestra:

```{r beta-binomial-muestra-total}
aceptacion_muestra_total <- bind_rows(
  aceptacion_muestra, aceptacion_muestra_2
) |>
  mutate(id_participante = row_number()) # Los ID están colapsados en una serie
```

### Pregunta 20

-   Obtén la distribución posterior analítica después de esta segunda muestra, represéntala junto con las distribuciones anteriores, y obtén los estimadores posteriores esperado y modal.

::: {#respuesta-20 .callout-note}
La suma de respuestas afirmativas de ambas muestras es $17+85=82$
La suma total de la muestra es $22+113=135$
Por lo tanto, al calcular los parámetros $αposterior$ y $βposterior$, obtenemos la misma distribución posterior que si hubiéramos trabajado con los datos combinados desde el principio.

```{r}
# Unimos las dos muestras
aceptacion_muestra_total <- bind_rows(
  aceptacion_muestra, aceptacion_muestra_2
) |> 
  mutate(id_participante = row_number())

# Contamos el número de respuestas afirmativas en la muestra total
y_total <- sum(aceptacion_muestra_total$resp_descarga_app == "Si")
n_total <- nrow(aceptacion_muestra_total)

# Parámetros de la distribución Beta a priori
alpha_prior <- 1
beta_prior <- 1

# Parámetros de la distribución Beta posterior para la muestra total
alpha_post_total <- alpha_prior + y_total
beta_post_total <- beta_prior + (n_total - y_total)

# Generar valores de p en el intervalo (0, 1)
p_values <- seq(0, 1, length.out = 1000)

# Calculamos las densidades de las distribuciones Beta a priori y posterior total
densidad_prior <- dbeta(p_values, shape1 = alpha_prior, shape2 = beta_prior)
densidad_post_total <- dbeta(p_values, shape1 = alpha_post_total, shape2 = beta_post_total)

# Graficamos las distribuciones
ggplot() +
  geom_line(aes(x = p_values, y = densidad_prior), color = "blue", size = 1.2, linetype = "dashed") +
  geom_line(aes(x = p_values, y = densidad_post_total), color = "green", size = 1.2) +
  labs(
    title = "Distribuciones Beta: A Priori vs Posterior Total",
    x = "Tasa de aceptación (p)",
    y = "Densidad",
    caption = "Distribución a priori (azul) y posterior total (verde)"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Valor esperado
esperado <- alpha_post_total / (alpha_post_total + beta_post_total)
cat("Valor esperado de la distribución posterior total: ", esperado, "\n")

# Moda
moda <- (alpha_post_total - 1) / (alpha_post_total + beta_post_total - 2)
cat("Moda de la distribución posterior total: ", moda, "\n")

```


:::

### Pregunta 21

-   ¿Qué concluyes de la respuesta anterior? ¿En qué se diferencia este enfoque del análisis de datos clásico o frecuentista?

::: {#respuesta-21 .callout-note}
En el análisis frecuentista, los parámetros del modelo se estiman utilizando los datos actuales sin incorporar ninguna información previa, es decir, sin $aprender$ de datos anteriores. Esto no es así cuando trabajamos con modelos bayesianos. Cuando trabajamos con modelos bayesianos, la distribución a posteriori se actualiza continuamente a medida que se incorporan nuevos datos. Así, en el análisis frecuentista la muestra es sólo un reflejo de la población y no cambia la probabilidad real, mientras que en el bayesiano la muestra ayuda a actualizar la creencia sobre la población. 
:::

# Ejercicio 4

*(NOTA: Para todas las distribuciones, utiliza el valor de `PREC` definido en el ejercicio 1.)*

En un proyecto de investigación educativo, el equipo investigador ha evaluado la rapidez de lectura en las dos clases de 1º de ESO de un colegio.
Los datos que te entregan consisten en el tiempo en segundos que tarda cada niño en leer un texto estandarizado.

Se quiere obtener un parámetro global promedio del tiempo de lectura para el alumnado de 1º de ESO en el colegio, para lo que te piden ajustar un modelo normal-normal.
Se pide usar como distribución previa la estimada de la población, que tiene media y varianza de 247 y 1156, respectivamente.

Los datos que te han facilitado son:

```{r normal-normal-muestras}
clase_1 <- tibble(
  id     = 1:27,
  tiempo = c(
    242, 249, 278, 273, 227, 257, 276, 236, 214, 141, 200, 201, 
    228, 271, 160, 275, 156, 246, 293, 306, 263, 247, 224, 160, 277, 
    168, 250
  )
)

clase_2 <- tibble(
  id     = 1:24,
  tiempo = c(
    195, 176, 237, 258, 226, 254, 292, 212, 215, 298, 235, 244, 
    144, 227, 166, 194, 261, 187, 224, 233, 180, 167, 193, 282
  )
)
```

## Modelo normal-normal

### Pregunta 22

-   Determina la verosimilitud y las distribuciones previa y posterior de la media, asumiendo que la varianza de la verosimilitud es la varianza de los datos. Justifica cómo has obtenido los parámetros de la distribución posterior (usa 2 decimales de precisión).

::: {#respuesta-22 .callout-note}
La media y la varianza nos ayuda a entender la distribución de los tiempos de cada clase. La distribución previa es la información que tenemos antes de observar los datos. En este caso, tenemos la información de la media poblacional de los tiempos de lectura, que es 247 segundos, y la varianza poblacional, que es 1156 segundos. Esto datos definen la distribución normal a priori de la media de los tiempos de lectura. Esto es lo que sabemos antes de observar las muestras. 

La distribución posterior es la que obtenemos después de observar los datos, es decir, es una actualización de nuestra creencia sobre la media poblacional $μ$ a partir de las observaciones de las dos clases.

Para obtener la distribución posterior, aplicamos el Teorema de Bayes. El Teorema de Bayes nos permite combinar la distribución previa con la información de los datos (en este caso, las medias muestrales de las dos clases).

La formula para la media posterior es: 
$$
\mathcal{\mu}_{\text{posterior}} = \frac{\left(\frac{n_1}{\sigma_0^2}\right) \mu_0 + \left(\frac{n_2}{\hat{\sigma}^2}\right) \bar{x}}{\left(\frac{n_1}{\sigma_0^2}\right) + \left(\frac{n_2}{\hat{\sigma}^2}\right)}
$$
Usamos la fórmula de Bayes para obtener la media posterior y su varianza posterior.

```{r}
# Datos de las clases
clase_1 <- c(242, 249, 278, 273, 227, 257, 276, 236, 214, 141, 200, 201, 
             228, 271, 160, 275, 156, 246, 293, 306, 263, 247, 224, 160, 277, 
             168, 250)

clase_2 <- c(195, 176, 237, 258, 226, 254, 292, 212, 215, 298, 235, 244, 
             144, 227, 166, 194, 261, 187, 224, 233, 180, 167, 193, 282)

# Medias y varianzas
n1 <- length(clase_1)
n2 <- length(clase_2)

# Calcular medias y varianzas muestrales
x_bar_1 <- mean(clase_1)
x_bar_2 <- mean(clase_2)

var_1 <- var(clase_1)
var_2 <- var(clase_2)

# Varianza combinada y media combinada
x_bar_combined <- mean(c(clase_1, clase_2))

# Media a priori y varianza a priori
mu_0 <- 247
sigma_0_sq <- 1156

# Fórmulas de la posterior
mu_posterior <- ((n1 / sigma_0_sq) * mu_0 + (n2 / var_1) * x_bar_combined) / ((n1 / sigma_0_sq) + (n2 / var_1))
sigma_posterior_sq <- 1 / ((n1 / sigma_0_sq) + (n2 / var_1))

# Resultados
mu_posterior
sigma_posterior_sq
```
El valor 240.6374 corresponde a la media posterior, y 28.62379 corresponde a la varianza posterior.

Para obtener la verosimilitud de la media $μ$, calculamos la función de densidad de probabilidad:
```{r verosimilitud}
# Definimos un valor para la media 
mu_test <- 250  # Usamos 250 porque está cerca de la media 247

# Calculamos la varianza muestral
var_1 <- var(clase_1)
var_2 <- var(clase_2)

# Calculamos la varianza combinada
var_combined <- (var_1 * (n1 - 1) + var_2 * (n2 - 1)) / (n1 + n2 - 2)

# Calculamos la verosimilitud para la media mu_test
likelihood_1 <- prod(dnorm(clase_1, mean = mu_test, sd = sqrt(var_1)))
likelihood_2 <- prod(dnorm(clase_2, mean = mu_test, sd = sqrt(var_2)))

# Verosimilitud total combinada
likelihood_combined <- likelihood_1 * likelihood_2

# Valor de la verosimilitud
likelihood_combined
```
:::

## Estimación

### Pregunta 23

-   Representa las distribuciones previa y posterior de la media; considera un eje que cubra 4 desviaciones típicas a cada lado de la media de la distribución previa. Obten el estimador esperado y modal a partir de esta distribución y compáralos con la solución analítica de la pregunta anterior.

::: {#respuesta-23 .callout-note}
Usamos la función $dnorm()$ para calcular la densidad de las distribuciones normal previa y posterior. La distribución previa se calcula con los parámetros $μ0=247$ y $σ0=34$, y la distribución posterior con los parámetros $μposterior=240.6374$ y $σposterior=5.35$
La distribución previa está representada en azul y la distribución posterior en rojo. 
Para una distribución normal, tanto el estimador esperado como el estimador modal coinciden con la media posterior. Así que el estimador esperado y modal es $μposterior=240.6374$
Este valor es el centro de la distribución posterior en el gráfico.
```{r}
# Parámetros de la distribución previa
mu0 <- 247        # media de la previa
sigma0_sq <- 1156 # varianza de la previa

# Parámetros de la distribución posterior (ya calculados previamente)
mu_posterior <- 240.6374  # media posterior
sigma_posterior_sq <- 28.62379  # varianza posterior

# Definimos los valores para el rango de la distribución
prec <- 1e-3 # Precisión

# Generamos una secuencia de valores para la variable (media) que queremos representar
x_vals <- seq(mu0 - 4*sqrt(sigma0_sq), mu0 + 4*sqrt(sigma0_sq), by = prec)

# Calculamos la densidad de la distribución normal previa
y_vals_prev <- dnorm(x_vals, mean = mu0, sd = sqrt(sigma0_sq))

# Calculamos la densidad de la distribución normal posterior
y_vals_post <- dnorm(x_vals, mean = mu_posterior, sd = sqrt(sigma_posterior_sq))

# Creamos un tibble para usar con ggplot
previa <- tibble(variable = x_vals, densidad = y_vals_prev)
posterior <- tibble(variable = x_vals, densidad = y_vals_post)

# Representamos la distribución previa y posterior
ggplot() +
  geom_line(data = previa, aes(x = variable, y = densidad), color = "blue") +
  geom_line(data = posterior, aes(x = variable, y = densidad), color = "red") +
  labs(title = "Distribuciones Previa y Posterior de la Media", 
       x = "Media (μ)", y = "Densidad") +
  theme_minimal()
```
:::
